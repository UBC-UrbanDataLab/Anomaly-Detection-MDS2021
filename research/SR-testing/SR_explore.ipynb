{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3810jvsc74a57bd07d2dde933846643c70a0971eba9e216bf0ce928f2ec74020d36b05b86c71e3e9",
   "display_name": "Python 3.8.10 64-bit ('pyinfluxdb': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "7d2dde933846643c70a0971eba9e216bf0ce928f2ec74020d36b05b86c71e3e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Spectral Residual Transformation Exploration\n",
    "\n",
    "This notebook explore using spectral residual transformations on datasets to assess if it could be useful for anomaly detection identification. The assessment is mainly visual and based on looking at figures. The plots in this notebook show the manually (subjectively) labelled anomalies for the datasets (discussed in `/data/labelled-skyspark-data`) overlaid on various transformations."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from sklearn.preprocessing import scale\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "source": [
    "Create a function to apply SR in conjunction with standardizing data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_SR(data, normal_first=False, SR=True, normal_last=False):\n",
    "    if normal_first:\n",
    "        data1 = scale(data)\n",
    "    else:\n",
    "        data1 = data.copy()\n",
    "        \n",
    "    # spectral residual transformation\n",
    "    if SR:\n",
    "        A = np.fft.fft(data1)\n",
    "        L = np.log(abs(A))\n",
    "        P = np.angle(A)\n",
    "        h = np.ones((7,),np.float32)/7\n",
    "        A_L = np.convolve(L, h, 'same')\n",
    "        R = L - A_L\n",
    "        S = np.square(abs(np.fft.ifft(np.exp(R + 1j*P))))\n",
    "    else:\n",
    "        S = data1.copy()\n",
    "    \n",
    "    if normal_last:\n",
    "        data_out = scale(S)\n",
    "    else:\n",
    "        data_out = S.copy()\n",
    "\n",
    "    return data_out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to read/apply transformation/save data\n",
    "def save_files(file_in, suffix, normal_first=False, SR=False, normal_last=False):\n",
    "    data = pd.read_csv('../../data/labelled-skyspark-data/' + file_in + '.csv', parse_dates = ['Datetime'])\n",
    "    data_trans = convert_SR(data.Value, normal_first=normal_first, SR=normal_first, normal_last=normal_first)\n",
    "    data_out = data.copy()\n",
    "    data_out['Value'] = data_trans\n",
    "    data_out.to_csv(file_in + '_' + suffix + '.csv', index = False)"
   ]
  },
  {
   "source": [
    "Create a function that provides a series of plots with various transformation applied including:\n",
    "\n",
    "1. only standardize data\n",
    "2. only apply spectral residual transformation\n",
    "3. standardize, then apply spectral residual\n",
    "4. apply spectral residual, then standardize"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_various(file_in, plot_portion = 'all'):\n",
    "    data = pd.read_csv('../../data/labelled-skyspark-data/' + file_in + '.csv', parse_dates = ['Datetime'])\n",
    "\n",
    "    trace1 = convert_SR(data.Value, normal_first=True, SR=False, normal_last=False)\n",
    "    trace2 = convert_SR(data.Value, normal_first=False, SR=True, normal_last=False)\n",
    "    trace3 = convert_SR(data.Value, normal_first=True, SR=True, normal_last=False)\n",
    "    trace4 = convert_SR(data.Value, normal_first=False, SR=True, normal_last=True)\n",
    "\n",
    "    if plot_portion == 'first_half':\n",
    "        start = 0\n",
    "        end = int(len(data)/2)\n",
    "\n",
    "    elif plot_portion == 'second_half':\n",
    "        start = int(len(data)/2)\n",
    "        end = len(data)\n",
    "    else:\n",
    "        start = 0\n",
    "        end = len(data)\n",
    "\n",
    "    fig = make_subplots(rows=1, cols=4, subplot_titles=(\"Standardize, No SR\", \n",
    "    \"No Standardize, SR\", \n",
    "    \"Standardize, then SR\", \n",
    "    \"SR, then Standardize\"))\n",
    "\n",
    "    fig.append_trace(go.Scattergl(\n",
    "        x = data['Datetime'][start:end],\n",
    "        y = trace1[start:end],\n",
    "        mode = 'markers',\n",
    "        marker=dict(color=1*data['Anomaly'][start:end])\n",
    "    ), row=1, col=1)\n",
    "\n",
    "    fig.append_trace(go.Scattergl(\n",
    "        x = data['Datetime'][start:end],\n",
    "        y = trace2[start:end],\n",
    "        mode = 'markers',\n",
    "        marker=dict(color=1*data['Anomaly'][start:end])\n",
    "    ), row=1, col=2)\n",
    "\n",
    "    fig.append_trace(go.Scattergl(\n",
    "        x = data['Datetime'][start:end],\n",
    "        y = trace3[start:end],\n",
    "        mode = 'markers',\n",
    "        marker=dict(color=1*data['Anomaly'][start:end])\n",
    "    ), row=1, col=3)\n",
    "\n",
    "    fig.append_trace(go.Scattergl(\n",
    "        x = data['Datetime'][start:end],\n",
    "        y = trace4[start:end],\n",
    "        mode = 'markers',\n",
    "        marker=dict(color=1*data['Anomaly'][start:end])\n",
    "    ), row=1, col=4)\n",
    "\n",
    "    fig.update_layout(height=500, width=1200,\n",
    "    margin=dict(\n",
    "        l=50,\n",
    "        r=50,\n",
    "        b=50,\n",
    "        t=50,\n",
    "        pad=2\n",
    "    ))\n",
    "    fig.show()"
   ]
  },
  {
   "source": [
    "## Look at Datasets with Transformations\n",
    "\n",
    "The following sections provide code to run on each of the datasets. The code is commented out as the plots a very large. The function was run creating plotly images (interactive), a snapshot of the image was taken and saved, and the images are shown below.\n",
    "\n",
    "The functions can be run to explore the data as required, but it is recommend to remove them before saving this notebook file."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_various('CEC_compiled_data_1b_updated')"
   ]
  },
  {
   "source": [
    "This figure is for the CEC HW Main Meter Power\n",
    "\n",
    "![](images/CEC_compiled_data_1b_updated.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "The plot indicates that applying SR appears to highlight the self-labelled anomalies. The figures also show that standardizing, then applying SR is potentially a better option as the other two options do not appear to show any anomalous data (visually shown in yellow) in the summer 2020 period."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_various('CEC_compiled_data_2b_updated')"
   ]
  },
  {
   "source": [
    "This figure is for the HW Main Meter Entering Water Temperature\n",
    "\n",
    "![](images/CEC_compiled_data_2b_updated.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "The figure shows that the SR transformations appear to help isolate the self-labelled anomalies. It is hard to determine which of the three options with SR is better."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_various('CEC_compiled_data_3b_updated', plot_portion='first_half')"
   ]
  },
  {
   "source": [
    "The following figures are for the CEC Main Meter Flow. Note that the data had to be split into two sets of figures due to the size of the data. The figure below is for the first half.\n",
    "\n",
    "![](images/CEC_compiled_data_3b_updated_first.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_various('CEC_compiled_data_3b_updated', plot_portion='second_half')"
   ]
  },
  {
   "source": [
    "The figure below is for the second half.\n",
    "\n",
    "![](images/CEC_compiled_data_3b_updated_second.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "The figures shows that the SR transformations appear to help isolate the self-labelled anomalies. It is hard to determine which of the three options with SR is better. The standardize, then SR appears to result in curvature to the general trend compared with the other SR options but I don't believe this would be an issue with the LSTM."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_various('CEC_compiled_data_4b_updated')"
   ]
  },
  {
   "source": [
    "The figure below is for the Boiler B-1 Gas Pressure.\n",
    "\n",
    "![](images/CEC_compiled_data_4b_updated.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "The figures indicate that all manually labelled anomalies are quite distinct. Once again the standardize, then SR appears to create curvature to the data but I don't believe this would be in issue for the LSTM."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_various('CEC_compiled_data_5b_updated')"
   ]
  },
  {
   "source": [
    "The following figure is for the Boiler B-1 Exhaust O2.\n",
    "\n",
    "![](images/CEC_compiled_data_5b_updated.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "The figure indicates that the SR transformation results in the data having a much similar pattern to the other datasets whereas the data that does not have an SR transformation is quite different. Again, the standardize, then SR has curvature in the data."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Comments based on above Plots\n",
    "\n",
    "The SR transformations do appear to highlight the self-labelled anomalies. It also highlights additional data that are potentially anomalous as well that were not manually (subjectively) picked out. This transformation appears to be potential option to apply with the LSTM and should be explored.\n",
    "\n",
    "The option where standardization is used before the SR transformation will likely be tried first but not applying any standardization would likely be the next one to try if standardize, then SR didn't work well."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell to save various options\n",
    "\n",
    "# normalize, then SR\n",
    "save_files('CEC_compiled_data_1b_updated', '_NormSR', normal_first=True, SR=True, normal_last=False)\n",
    "save_files('CEC_compiled_data_2b_updated', '_NormSR', normal_first=True, SR=True, normal_last=False)\n",
    "save_files('CEC_compiled_data_3b_updated', '_NormSR', normal_first=True, SR=True, normal_last=False)\n",
    "save_files('CEC_compiled_data_4b_updated', '_NormSR', normal_first=True, SR=True, normal_last=False)\n",
    "save_files('CEC_compiled_data_5b_updated', '_NormSR', normal_first=True, SR=True, normal_last=False)\n"
   ]
  },
  {
   "source": [
    "## Interactive Inspection of Data\n",
    "\n",
    "The [interactive app](../../code/labeller-app/) was also used to explore the transformed data in comparison with the untransformed datasets in `/data/labelled-skyspark-data`. Based on the inspection the SR transformation appears to do a good job of highlighting spikes or sharp breaks in data (as was noted in the above plots). Howevever, one area it does not appear to do well is with odd looking data that did not fluctuate out the range of nearby data.\n",
    "\n",
    "For example, the plot below shows anomalous flatline data. However, the plot where the data is transformed using SR, this anomalous data is now not flatlined potentially making it much harder for the LSTM to pick it up."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "![](images/noSR_1.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "![](images/SR_1.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Conversely, the transformation does a good job of picking up a piece of data that is clearly not inline with it's surrounding data as shown in the two figures below (first figure is the normal untransformed data and the second has SR applied)\n",
    "\n",
    "![](images/noSR_2.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "![](images/SR_2.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}