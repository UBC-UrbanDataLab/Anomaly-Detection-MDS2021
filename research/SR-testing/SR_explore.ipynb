{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3810jvsc74a57bd07d2dde933846643c70a0971eba9e216bf0ce928f2ec74020d36b05b86c71e3e9",
   "display_name": "Python 3.8.10 64-bit ('pyinfluxdb': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "7d2dde933846643c70a0971eba9e216bf0ce928f2ec74020d36b05b86c71e3e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from sklearn.preprocessing import scale\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_SR(data, normal_first=False, SR=True, normal_last=False):\n",
    "    if normal_first:\n",
    "        data1 = scale(data)\n",
    "    else:\n",
    "        data1 = data.copy()\n",
    "\n",
    "    if SR:\n",
    "        A = np.fft.fft(data1)\n",
    "        L = np.log(abs(A))\n",
    "        P = np.angle(A)\n",
    "        h = np.ones((7,),np.float32)/7\n",
    "        A_L = np.convolve(L, h, 'same')\n",
    "        R = L - A_L\n",
    "        S = np.square(abs(np.fft.ifft(np.exp(R + 1j*P))))\n",
    "    else:\n",
    "        S = data1.copy()\n",
    "    \n",
    "    if normal_last:\n",
    "        data_out = scale(S)\n",
    "    else:\n",
    "        data_out = S.copy()\n",
    "\n",
    "    return data_out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_files(file_in, suffix, normal_first=False, SR=False, normal_last=False):\n",
    "    data = pd.read_csv('../../data/labelled-skyspark-data/' + file_in + '.csv', parse_dates = ['Datetime'])\n",
    "    data_trans = convert_SR(data.Value, normal_first=normal_first, SR=normal_first, normal_last=normal_first)\n",
    "    data_out = data.copy()\n",
    "    data_out['Value'] = data_trans\n",
    "    data_out.to_csv(file_in + '_' + suffix + '.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_various(file_in, plot_portion = 'all'):\n",
    "    data = pd.read_csv('../../data/labelled-skyspark-data/' + file_in + '.csv', parse_dates = ['Datetime'])\n",
    "\n",
    "    trace1 = convert_SR(data.Value, normal_first=True, SR=False, normal_last=False)\n",
    "    trace2 = convert_SR(data.Value, normal_first=False, SR=True, normal_last=False)\n",
    "    trace3 = convert_SR(data.Value, normal_first=True, SR=True, normal_last=False)\n",
    "    trace4 = convert_SR(data.Value, normal_first=False, SR=True, normal_last=True)\n",
    "\n",
    "    if plot_portion == 'first_half':\n",
    "        start = 0\n",
    "        end = int(len(data)/2)\n",
    "\n",
    "    elif plot_portion == 'second_half':\n",
    "        start = int(len(data)/2)\n",
    "        end = len(data)\n",
    "    else:\n",
    "        start = 0\n",
    "        end = len(data)\n",
    "\n",
    "    fig = make_subplots(rows=1, cols=4, subplot_titles=(\"Standardize, No SR\", \n",
    "    \"No Standardize, SR\", \n",
    "    \"Standardize, then SR\", \n",
    "    \"SR, then Standardize\"))\n",
    "\n",
    "    fig.append_trace(go.Scattergl(\n",
    "        x = data['Datetime'][start:end],\n",
    "        y = trace1[start:end],\n",
    "        mode = 'markers',\n",
    "        marker=dict(color=1*data['Anomaly'][start:end])\n",
    "    ), row=1, col=1)\n",
    "\n",
    "    fig.append_trace(go.Scattergl(\n",
    "        x = data['Datetime'][start:end],\n",
    "        y = trace2[start:end],\n",
    "        mode = 'markers',\n",
    "        marker=dict(color=1*data['Anomaly'][start:end])\n",
    "    ), row=1, col=2)\n",
    "\n",
    "    fig.append_trace(go.Scattergl(\n",
    "        x = data['Datetime'][start:end],\n",
    "        y = trace3[start:end],\n",
    "        mode = 'markers',\n",
    "        marker=dict(color=1*data['Anomaly'][start:end])\n",
    "    ), row=1, col=3)\n",
    "\n",
    "    fig.append_trace(go.Scattergl(\n",
    "        x = data['Datetime'][start:end],\n",
    "        y = trace4[start:end],\n",
    "        mode = 'markers',\n",
    "        marker=dict(color=1*data['Anomaly'][start:end])\n",
    "    ), row=1, col=4)\n",
    "\n",
    "    fig.update_layout(height=500, width=1200,\n",
    "    margin=dict(\n",
    "        l=50,\n",
    "        r=50,\n",
    "        b=50,\n",
    "        t=50,\n",
    "        pad=2\n",
    "    ))\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_various('CEC_compiled_data_1b_updated')"
   ]
  },
  {
   "source": [
    "![](images/CEC_compiled_data_1b_updated.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_various('CEC_compiled_data_2b_updated')"
   ]
  },
  {
   "source": [
    "![](images/CEC_compiled_data_2b_updated.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_various('CEC_compiled_data_3b_updated', plot_portion='first_half')"
   ]
  },
  {
   "source": [
    "![](images/CEC_compiled_data_3b_updated_first.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_various('CEC_compiled_data_3b_updated', plot_portion='second_half')"
   ]
  },
  {
   "source": [
    "![](images/CEC_compiled_data_3b_updated_second.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_various('CEC_compiled_data_4b_updated')"
   ]
  },
  {
   "source": [
    "![](images/CEC_compiled_data_4b_updated.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_various('CEC_compiled_data_5b_updated')"
   ]
  },
  {
   "source": [
    "![](images/CEC_compiled_data_5b_updated.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell to save various options\n",
    "\n",
    "# normalize, then SR\n",
    "save_files('CEC_compiled_data_1b_updated', '_NormSR', normal_first=True, SR=True, normal_last=False)\n",
    "save_files('CEC_compiled_data_2b_updated', '_NormSR', normal_first=True, SR=True, normal_last=False)\n",
    "save_files('CEC_compiled_data_3b_updated', '_NormSR', normal_first=True, SR=True, normal_last=False)\n",
    "save_files('CEC_compiled_data_4b_updated', '_NormSR', normal_first=True, SR=True, normal_last=False)\n",
    "save_files('CEC_compiled_data_5b_updated', '_NormSR', normal_first=True, SR=True, normal_last=False)\n"
   ]
  }
 ]
}