{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediciton Timer Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Timer Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "time taken to load packages :  6.486962080001831\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# files are contained in a sibling folder\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import model.clean as cl\n",
    "import model.model_trainer as mt\n",
    "import model.model_predict as mp\n",
    "from model.influx_interact import influx_class\n",
    "\n",
    "from tensorflow.random import set_seed\n",
    "set_seed(2)\n",
    "print(\"time taken to load packages : \", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# END TIME FOR TRAINING SET BECOMES PREDICTING'S START TIME\n",
    "START_TIME = 1613109600\n",
    "END_TIME = 1613196000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME_STEP_SIZES = {\n",
    "    \"Campus Energy Centre Campus HW Main Meter Flow\":15,\n",
    "}\n",
    "THRESHOLD_RATIOS = {\n",
    "    \"Campus Energy Centre Campus HW Main Meter Flow\": 1.72,\n",
    "}\n",
    "measurement_name = \"test_timer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "time taken to read from influx  0.15479683876037598\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "model_path = \"./test_env_models/\"\n",
    "scaler_path = \"./test_env_standardizers/\"\n",
    "percentile_path = \"./test_env_loss_percentiles/\"\n",
    "\n",
    "# setup InfluxDB client\n",
    "token = \"mytoken\"\n",
    "org = \"UBC\"\n",
    "bucket = \"MDS2021\"\n",
    "url = \"http://localhost:8086\"\n",
    "\n",
    "influx_conn = influx_class(\n",
    "    org=org,\n",
    "    url=url,\n",
    "    bucket=bucket,\n",
    "    token=token,\n",
    ")\n",
    "\n",
    "influx_read_df = influx_conn.make_query(\n",
    "    location=\"Campus Energy Centre\",\n",
    "    measurement=\"READINGS\",\n",
    "    id=[\"Campus Energy Centre Campus HW Main Meter Flow\"],\n",
    "    start=START_TIME,\n",
    "    end=END_TIME,\n",
    ")\n",
    "\n",
    "print(\"time taken to read from influx \", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "time taken to make predictions  1.2060463428497314\ntime taken to write predictions  0.05940604209899902\n"
     ]
    }
   ],
   "source": [
    "dfs_for_test = cl.split_sensors(influx_read_df)\n",
    "\n",
    "for key, df in dfs_for_test.items():\n",
    "    prediction_start_time = time.time()\n",
    "    dfs_for_test[key][\"Stand_Val\"] = cl.std_val_predict(\n",
    "        dfs_for_test[key][[\"Value\"]],\n",
    "        dfs_for_test[key][\"ID\"].any(),\n",
    "        scaler_path,\n",
    "    )\n",
    "    \n",
    "\n",
    "    # keeps external packages updated in\n",
    "    import importlib\n",
    "    importlib.reload(mp)\n",
    "\n",
    "    # sets up sequencing\n",
    "    time_steps = TIME_STEP_SIZES[key]\n",
    "    window_size = 1\n",
    "    x_train, y_train = mt.create_sequences(df[\"Stand_Val\"], df[\"Stand_Val\"], time_steps, window_size)\n",
    "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "\n",
    "    # set up lists for passing to predict\n",
    "    timestamps = df[\"DateTime\"].tail(len(df) - x_train.shape[1]+1).values\n",
    "    val_nums = df[\"Value\"].tail(len(df) - x_train.shape[1]+1).values\n",
    "\n",
    "    # gets training loss percentile for threshold setting\n",
    "    loss_percentile = cl.load_loss_percentile(key, file_path=percentile_path)\n",
    "    threshold = THRESHOLD_RATIOS[key] * loss_percentile\n",
    "\n",
    "\n",
    "    # predicting and prediction formatting\n",
    "    pred_df = mp.make_prediction(\n",
    "        key,\n",
    "        x_train,\n",
    "        timestamps,\n",
    "        threshold,\n",
    "        val_nums,\n",
    "        model_path,\n",
    "        anomaly_type=\"realtime_anomaly\"\n",
    "    )\n",
    "    pred_df = pred_df[[\"uniqueID\", \"val_num\", \"realtime_anomaly\"]]\n",
    "    print(\"time taken to make predictions \", time.time()- prediction_start_time)\n",
    "\n",
    "    write_start_time = time.time()\n",
    "    influx_conn.write_data(pred_df, measurement_name, tags=[\"uniqueID\", \"realtime_anomaly\"])\n",
    "    print(\"time taken to write predictions \", time.time()- write_start_time)\n",
    "influx_conn.client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}