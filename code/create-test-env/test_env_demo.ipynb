{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Walkthrough of the test env code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from influxdb_client import InfluxDBClient\n",
    "from influxdb_client.client.write_api import SYNCHRONOUS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import files from sibling a directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"..\")\n",
    "\n",
    "import model.clean as cl\n",
    "import model.model_trainer as mt\n",
    "import model.model_predict as mp\n",
    "from model.influx_interact import influx_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1\n",
    "Set up a local instance of influx by following the README.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2  \n",
    "`populate_influx.py`  \n",
    "Populating influx with data from csvs stored in the repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_CSVS = \"../../data/labelled-skyspark-data/\"\n",
    "CSVS_TO_LOAD = [\n",
    "    \"CEC_compiled_data_1b_updated.csv\",\n",
    "    \"CEC_compiled_data_2b_updated.csv\",\n",
    "    \"CEC_compiled_data_3b_updated.csv\",\n",
    "    \"CEC_compiled_data_4b_updated.csv\",\n",
    "    \"CEC_compiled_data_5b_updated.csv\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up influx connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as set up in the docker-compose\n",
    "token = \"mytoken\"\n",
    "org = \"UBC\"\n",
    "bucket = \"MDS2021\"\n",
    "\n",
    "# set up influx\n",
    "client = InfluxDBClient(url=\"http://localhost:8086\", token=token, timeout=10_000_000)\n",
    "write_api = client.write_api(write_options=SYNCHRONOUS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop over each csv, read it then write it into influx  \n",
    "\n",
    "Important note: If the influx write times out, re-run and it should work on second try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing: CEC_compiled_data_1b_updated.csv\n",
      "writing: CEC_compiled_data_2b_updated.csv\n",
      "writing: CEC_compiled_data_3b_updated.csv\n",
      "writing: CEC_compiled_data_4b_updated.csv\n",
      "writing: CEC_compiled_data_5b_updated.csv\n"
     ]
    }
   ],
   "source": [
    "for csv in CSVS_TO_LOAD:\n",
    "\n",
    "    # load and set up dataframes\n",
    "    df = pd.read_csv(PATH_TO_CSVS + csv, parse_dates=[\"Datetime\"])\n",
    "    df.rename(columns={\"Value\": \"val_num\"}, inplace=True)\n",
    "    df.rename(columns={\"ID\": \"uniqueID\"}, inplace=True)\n",
    "    df.rename(columns={\"Anomaly\": \"AH\"}, inplace=True)\n",
    "    df[\"navName\"] = \"Energy\"\n",
    "    df[\"siteRef\"] = \"Campus Energy Centre\"\n",
    "    df.set_index(\"Datetime\", drop=True, inplace=True)\n",
    "    df = df.drop([\"AH\"], axis=1)\n",
    "\n",
    "    print(\"writing: {}\".format(csv))\n",
    "    # write values\n",
    "    write_api.write(\n",
    "        bucket,\n",
    "        org,\n",
    "        record=df,\n",
    "        data_frame_measurement_name=\"READINGS\",\n",
    "        data_frame_tag_columns=[\"uniqueID\", \"navName\", \"siteRef\"],\n",
    "    )\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the `df` object to see what was written to influx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val_num</th>\n",
       "      <th>uniqueID</th>\n",
       "      <th>navName</th>\n",
       "      <th>siteRef</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-01 07:45:00</th>\n",
       "      <td>2.9</td>\n",
       "      <td>Campus Energy Centre Boiler B-1 Exhaust O2</td>\n",
       "      <td>Energy</td>\n",
       "      <td>Campus Energy Centre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 08:00:00</th>\n",
       "      <td>2.9</td>\n",
       "      <td>Campus Energy Centre Boiler B-1 Exhaust O2</td>\n",
       "      <td>Energy</td>\n",
       "      <td>Campus Energy Centre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 08:15:00</th>\n",
       "      <td>2.9</td>\n",
       "      <td>Campus Energy Centre Boiler B-1 Exhaust O2</td>\n",
       "      <td>Energy</td>\n",
       "      <td>Campus Energy Centre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 08:30:00</th>\n",
       "      <td>2.9</td>\n",
       "      <td>Campus Energy Centre Boiler B-1 Exhaust O2</td>\n",
       "      <td>Energy</td>\n",
       "      <td>Campus Energy Centre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 08:45:00</th>\n",
       "      <td>2.9</td>\n",
       "      <td>Campus Energy Centre Boiler B-1 Exhaust O2</td>\n",
       "      <td>Energy</td>\n",
       "      <td>Campus Energy Centre</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     val_num                                    uniqueID  \\\n",
       "Datetime                                                                   \n",
       "2020-01-01 07:45:00      2.9  Campus Energy Centre Boiler B-1 Exhaust O2   \n",
       "2020-01-01 08:00:00      2.9  Campus Energy Centre Boiler B-1 Exhaust O2   \n",
       "2020-01-01 08:15:00      2.9  Campus Energy Centre Boiler B-1 Exhaust O2   \n",
       "2020-01-01 08:30:00      2.9  Campus Energy Centre Boiler B-1 Exhaust O2   \n",
       "2020-01-01 08:45:00      2.9  Campus Energy Centre Boiler B-1 Exhaust O2   \n",
       "\n",
       "                    navName               siteRef  \n",
       "Datetime                                           \n",
       "2020-01-01 07:45:00  Energy  Campus Energy Centre  \n",
       "2020-01-01 08:00:00  Energy  Campus Energy Centre  \n",
       "2020-01-01 08:15:00  Energy  Campus Energy Centre  \n",
       "2020-01-01 08:30:00  Energy  Campus Energy Centre  \n",
       "2020-01-01 08:45:00  Energy  Campus Energy Centre  "
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now sensor data has been written to influx's READINGS bucket  \n",
    "This simulates what UDL's influx will look like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3\n",
    "`test_env_scheduled_training.py`  \n",
    "Run the training file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subset the training data for fast dev iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "TESTING = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup thresholds for anomaly detection.  \n",
    "If a training example's loss is greater than the set threshold it will be flagged as anomalous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLDS = {\n",
    "    \"Campus Energy Centre Campus HW Main Meter Power\": 0.09,\n",
    "    \"Campus Energy Centre Boiler B-1 Exhaust O2\": 0.019,\n",
    "    \"Campus Energy Centre Boiler B-1 Gas Pressure\": 0.0725,\n",
    "    \"Campus Energy Centre Campus HW Main Meter Entering Water Temperature\": 0.02938,\n",
    "    \"Campus Energy Centre Campus HW Main Meter Flow\": 0.043,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick a end time for the readings to be used for training  \n",
    "In the real implementation there will be no end_time for the training data, i.e it will train on all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "END_TIME = 1613109600"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore training with removing anomalous records, i.e only train on normal data for this specific sensor data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "REMOVE_ANOMALOUS = False\n",
    "REMOVE_ANOMALOUS_DATA = [\n",
    "    \"Campus Energy Centre Campus HW Main Meter Entering Water Temperature\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Influx connector setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"./test_env_models/\"\n",
    "scaler_path = \"./test_env_standardizers/\"\n",
    "\n",
    "# set up for influx\n",
    "token = \"mytoken\"\n",
    "org = \"UBC\"\n",
    "bucket = \"MDS2021\"\n",
    "url = \"http://localhost:8086\"\n",
    "\n",
    "influx_conn = influx_class(\n",
    "    org=org,\n",
    "    url=url,\n",
    "    bucket=bucket,\n",
    "    token=token,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the training data from influx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "influx_read_df = influx_conn.make_query(\n",
    "    location=\"Campus Energy Centre\",\n",
    "    measurement=\"READINGS\",\n",
    "    end=END_TIME,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data based on sensor ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_bucket = cl.split_sensors(influx_read_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the `main_bucket` object is a dict with the name of the sensor as the key and then the value is another dict of data objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Campus Energy Centre Boiler B-1 Exhaust O2', 'Campus Energy Centre Boiler B-1 Gas Pressure', 'Campus Energy Centre Campus HW Main Meter Entering Water Temperature', 'Campus Energy Centre Campus HW Main Meter Flow', 'Campus Energy Centre Campus HW Main Meter Power'])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_bucket.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following cell for training:\n",
    "1) Iterates over each the data sets (line 1)  \n",
    "2) Removes anomalous data if the data set has been specified (lines 4-23)  \n",
    "3) Standardizes the values for training and saves the standardizer for the prediction step (lines 25-30)  \n",
    "4) Subsets the data for faster training if specified (lines 32-33)  \n",
    "5) Sequences the values into windows for the LSTM (lines 35-37)  \n",
    "6) Fits and saves the model (line 42)  \n",
    "7) Writes the resulting data (that contains: value, anomalies detected manually, and anomalies detected in training) to influx (lines 44-57)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for : Campus Energy Centre Boiler B-1 Exhaust O2\n",
      "Epoch 1/100\n",
      "141/141 [==============================] - 6s 24ms/step - loss: 9.4735e-04 - val_loss: 1.3975\n",
      "Epoch 2/100\n",
      "141/141 [==============================] - 3s 22ms/step - loss: 5.7357e-04 - val_loss: 1.4223\n",
      "Epoch 3/100\n",
      "141/141 [==============================] - 3s 23ms/step - loss: 2.6858e-04 - val_loss: 1.4247\n",
      "Epoch 4/100\n",
      "141/141 [==============================] - 3s 21ms/step - loss: 1.4280e-04 - val_loss: 1.4246\n",
      "Training for : Campus Energy Centre Boiler B-1 Gas Pressure\n",
      "Epoch 1/100\n",
      "141/141 [==============================] - 6s 22ms/step - loss: 0.2734 - val_loss: 0.3282\n",
      "Epoch 2/100\n",
      "141/141 [==============================] - 3s 20ms/step - loss: 0.2148 - val_loss: 0.3221\n",
      "Epoch 3/100\n",
      "141/141 [==============================] - 3s 22ms/step - loss: 0.2071 - val_loss: 0.3291\n",
      "Epoch 4/100\n",
      "141/141 [==============================] - 3s 22ms/step - loss: 0.2067 - val_loss: 0.3151\n",
      "Epoch 5/100\n",
      "141/141 [==============================] - 3s 23ms/step - loss: 0.2029 - val_loss: 0.3665\n",
      "Epoch 6/100\n",
      "141/141 [==============================] - 3s 22ms/step - loss: 0.2024 - val_loss: 0.3494\n",
      "Epoch 7/100\n",
      "141/141 [==============================] - 3s 22ms/step - loss: 0.2014 - val_loss: 0.3933\n",
      "Training for : Campus Energy Centre Campus HW Main Meter Entering Water Temperature\n",
      "Epoch 1/100\n",
      "141/141 [==============================] - 6s 24ms/step - loss: 0.1104 - val_loss: 0.0644\n",
      "Epoch 2/100\n",
      "141/141 [==============================] - 3s 21ms/step - loss: 0.0707 - val_loss: 0.0492\n",
      "Epoch 3/100\n",
      "141/141 [==============================] - 3s 22ms/step - loss: 0.0647 - val_loss: 0.0788\n",
      "Epoch 4/100\n",
      "141/141 [==============================] - 3s 22ms/step - loss: 0.0645 - val_loss: 0.0568\n",
      "Epoch 5/100\n",
      "141/141 [==============================] - 3s 21ms/step - loss: 0.0598 - val_loss: 0.0598\n",
      "Training for : Campus Energy Centre Campus HW Main Meter Flow\n",
      "Epoch 1/100\n",
      "141/141 [==============================] - 6s 23ms/step - loss: 0.2955 - val_loss: 0.1142\n",
      "Epoch 2/100\n",
      "141/141 [==============================] - 3s 20ms/step - loss: 0.2724 - val_loss: 0.2214\n",
      "Epoch 3/100\n",
      "141/141 [==============================] - 3s 22ms/step - loss: 0.2403 - val_loss: 0.3723\n",
      "Epoch 4/100\n",
      "141/141 [==============================] - 3s 23ms/step - loss: 0.2378 - val_loss: 0.4612\n",
      "Training for : Campus Energy Centre Campus HW Main Meter Power\n",
      "Epoch 1/100\n",
      "141/141 [==============================] - 6s 24ms/step - loss: 0.2886 - val_loss: 0.2397\n",
      "Epoch 2/100\n",
      "141/141 [==============================] - 3s 20ms/step - loss: 0.2468 - val_loss: 0.2209\n",
      "Epoch 3/100\n",
      "141/141 [==============================] - 3s 22ms/step - loss: 0.2159 - val_loss: 0.1908\n",
      "Epoch 4/100\n",
      "141/141 [==============================] - 3s 22ms/step - loss: 0.1982 - val_loss: 0.1766\n",
      "Epoch 5/100\n",
      "141/141 [==============================] - 3s 22ms/step - loss: 0.1916 - val_loss: 0.1669\n",
      "Epoch 6/100\n",
      "141/141 [==============================] - 3s 22ms/step - loss: 0.1834 - val_loss: 0.1582\n",
      "Epoch 7/100\n",
      "141/141 [==============================] - 3s 23ms/step - loss: 0.1829 - val_loss: 0.1539\n",
      "Epoch 8/100\n",
      "141/141 [==============================] - 3s 21ms/step - loss: 0.1777 - val_loss: 0.1475\n",
      "Epoch 9/100\n",
      "141/141 [==============================] - 3s 22ms/step - loss: 0.1781 - val_loss: 0.1461\n",
      "Epoch 10/100\n",
      "141/141 [==============================] - 3s 23ms/step - loss: 0.1747 - val_loss: 0.1487\n",
      "Epoch 11/100\n",
      "141/141 [==============================] - 3s 22ms/step - loss: 0.1703 - val_loss: 0.1454\n",
      "Epoch 12/100\n",
      "141/141 [==============================] - 3s 22ms/step - loss: 0.1711 - val_loss: 0.1412\n",
      "Epoch 13/100\n",
      "141/141 [==============================] - 3s 23ms/step - loss: 0.1699 - val_loss: 0.1341\n",
      "Epoch 14/100\n",
      "141/141 [==============================] - 3s 23ms/step - loss: 0.1647 - val_loss: 0.1326\n",
      "Epoch 15/100\n",
      "141/141 [==============================] - 3s 20ms/step - loss: 0.1637 - val_loss: 0.1332\n",
      "Epoch 16/100\n",
      "141/141 [==============================] - 3s 22ms/step - loss: 0.1625 - val_loss: 0.1328\n",
      "Epoch 17/100\n",
      "141/141 [==============================] - 3s 23ms/step - loss: 0.1658 - val_loss: 0.1332\n"
     ]
    }
   ],
   "source": [
    "for key, df in main_bucket.items():\n",
    "    print(\"Training for : {}\".format(key))\n",
    "\n",
    "    # removes anomalies to only train on normal data\n",
    "    if REMOVE_ANOMALOUS:\n",
    "        if key in REMOVE_ANOMALOUS_DATA:\n",
    "            PATH_TO_CSVS = \"../../data/labelled-skyspark-data/\"\n",
    "            csv = \"CEC_compiled_data_2b_updated.csv\"\n",
    "            df_with_manual_anomaly = pd.read_csv(\n",
    "                PATH_TO_CSVS + csv, parse_dates=[\"Datetime\"]\n",
    "            )\n",
    "            df_with_manual_anomaly[\"Datetime\"] = pd.to_datetime(\n",
    "                df_with_manual_anomaly[\"Datetime\"], utc=True\n",
    "            )\n",
    "            df = df.merge(\n",
    "                df_with_manual_anomaly[[\"Datetime\", \"Anomaly\"]],\n",
    "                how=\"left\",\n",
    "                left_on=\"DateTime\",\n",
    "                right_on=\"Datetime\",\n",
    "            )\n",
    "            df = df.loc[df[\"Anomaly\"] == False]\n",
    "            df = df.drop(columns=[\"DateTime\"], axis=1)\n",
    "            am_df.rename(columns={\"Anomaly\": \"manual_anomaly\"}, inplace=True)\n",
    "\n",
    "    # creates standardized column for each sensor in main bucket\n",
    "    df[\"Stand_Val\"] = cl.std_val_train(\n",
    "        df[[\"Value\"]],\n",
    "        main_bucket[key][\"ID\"].any(),\n",
    "        scaler_path,\n",
    "    )\n",
    "\n",
    "    if TESTING:\n",
    "        df = df.tail(5000)\n",
    "\n",
    "    # creates arrays for sliding windows\n",
    "    x_train, y_train = mt.create_sequences(df[\"Stand_Val\"], df[\"Stand_Val\"])\n",
    "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "\n",
    "    normal_dict = cl.model_parser(df, x_train, y_train)\n",
    "\n",
    "    threshold = THRESHOLDS[key]\n",
    "    mt.fit_models(normal_dict, model_path, threshold)\n",
    "\n",
    "    # for writing AM to influx\n",
    "    am_df = normal_dict[key][\"train_score_df\"]\n",
    "    am_df.rename(columns={\"anomaly\": \"model_anomaly\"}, inplace=True)\n",
    "    am_df.rename(columns={\"ID\": \"uniqueID\"}, inplace=True)\n",
    "    am_df.rename(columns={\"Datetime\": \"DateTime\"}, inplace=True)\n",
    "    am_df[\"val_num\"] = df[\"Value\"].iloc[x_train.shape[1] :]\n",
    "    # only if it hasnt already been created earlier\n",
    "    if \"manual_anomaly\" not in set(am_df.columns):\n",
    "        am_df[\"manual_anomaly\"] = False\n",
    "    am_df.set_index(\"DateTime\", drop=True, inplace=True)\n",
    "    am_df = am_df[[\"uniqueID\", \"model_anomaly\", \"val_num\", \"manual_anomaly\"]]\n",
    "\n",
    "    influx_conn.write_data(am_df, \"TRAINING_ANOMALY\", tags=[\"uniqueID\", \"model_anomaly\", \"manual_anomaly\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4\n",
    "`test_env_scheduled_predictor.py`  \n",
    "Create predictions and write to influx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up start and end times for the prediction data set in the test env.  \n",
    "In the real implementation END_TIME would be `now()` and START_TIME would be `now() - 1d`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# END TIME FOR TRAINING SET BECOMES PREDICTING'S START TIME\n",
    "START_TIME = 1613109600\n",
    "END_TIME = 1613196000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the data to be predicted on from influx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading data from influx\n"
     ]
    }
   ],
   "source": [
    "print(\"reading data from influx\")\n",
    "influx_read_df = influx_conn.make_query(\n",
    "    location=\"Campus Energy Centre\",\n",
    "    measurement=\"READINGS\",\n",
    "    start=START_TIME,\n",
    "    end=END_TIME,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split based on data name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_bucket = cl.split_sensors(influx_read_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following cell for predicting:\n",
    "1) Iterates over each the data sets (line 1)  \n",
    "2) Standardizes the values for training by loading the standardizer from the training step (lines 2-6)     \n",
    "3) Sequences the values into windows for the LSTM and other reshaping for the prediction step(lines 8-14)  \n",
    "4) Creates predictions for the data and returns the prediction object (lines 16-24)   \n",
    "5) Shapes the prediction object for writing back to influx (a dataframe that contains, value, and the prediction of anomalous) (lines 26-34) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Campus Energy Centre Boiler B-1 Exhaust O2\n",
      "(96, 5)\n",
      "Campus Energy Centre Boiler B-1 Gas Pressure\n",
      "(132, 5)\n",
      "Campus Energy Centre Campus HW Main Meter Entering Water Temperature\n",
      "(296, 5)\n",
      "Campus Energy Centre Campus HW Main Meter Flow\n",
      "(1386, 5)\n",
      "Campus Energy Centre Campus HW Main Meter Power\n",
      "(660, 5)\n"
     ]
    }
   ],
   "source": [
    "for key, df in main_bucket.items():\n",
    "    print(key)\n",
    "    main_bucket[key][\"Stand_Val\"] = cl.std_val_predict(\n",
    "        main_bucket[key][[\"Value\"]],\n",
    "        main_bucket[key][\"ID\"].any(),\n",
    "        scaler_path,\n",
    "    )\n",
    "    print(main_bucket[key].shape)\n",
    "\n",
    "    # creates arrays for sliding windows\n",
    "    x_train, y_train = mt.create_sequences(\n",
    "        main_bucket[key][\"Stand_Val\"], main_bucket[key][\"Stand_Val\"]\n",
    "    )\n",
    "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "    timestamps = df[\"DateTime\"].tail(len(df) - x_train.shape[1]).values\n",
    "    threshold = THRESHOLDS[key]\n",
    "\n",
    "    # predicting and prediction formatting\n",
    "    pred = mp.make_prediction(\n",
    "        key,\n",
    "        x_train,\n",
    "        timestamps,\n",
    "        threshold,\n",
    "        model_path,\n",
    "    )\n",
    "    ar_df = pd.DataFrame.from_dict(pred[\"data\"])\n",
    "\n",
    "    # prep for writing\n",
    "    ar_df.rename(columns={\"anomaly\": \"realtime_anomaly\"}, inplace=True)\n",
    "    ar_df.rename(columns={\"Timestamp\": \"DateTime\"}, inplace=True)\n",
    "    ar_df[\"uniqueID\"] = key\n",
    "    ar_df.set_index(\"DateTime\", drop=True, inplace=True)\n",
    "    ar_df[\"val_num\"] = df[\"Value\"].tail(len(df) - x_train.shape[1]).values\n",
    "    ar_df = ar_df[[\"uniqueID\", \"val_num\", \"realtime_anomaly\"]]\n",
    "\n",
    "    influx_conn.write_data(ar_df, \"PREDICT_ANOMALY\", tags=[\"uniqueID\", \"realtime_anomaly\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test environment will now have three readings:  \n",
    "READINGS: the raw data  \n",
    "TRAINING_ANOMALY: data with anomalies flag manually and during the training  \n",
    "PREDICT_ANOMALY: data with anomalies detected by the prediction step  \n",
    "\n",
    "As well as a standardizer and a model for each data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniqueID</th>\n",
       "      <th>val_num</th>\n",
       "      <th>realtime_anomaly</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DateTime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1613112271000000000</th>\n",
       "      <td>Campus Energy Centre Campus HW Main Meter Power</td>\n",
       "      <td>39.900002</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1613112564000000000</th>\n",
       "      <td>Campus Energy Centre Campus HW Main Meter Power</td>\n",
       "      <td>38.200001</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1613112600000000000</th>\n",
       "      <td>Campus Energy Centre Campus HW Main Meter Power</td>\n",
       "      <td>38.299999</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1613112877000000000</th>\n",
       "      <td>Campus Energy Centre Campus HW Main Meter Power</td>\n",
       "      <td>39.799999</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1613113200000000000</th>\n",
       "      <td>Campus Energy Centre Campus HW Main Meter Power</td>\n",
       "      <td>39.200001</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1613195579000000000</th>\n",
       "      <td>Campus Energy Centre Campus HW Main Meter Power</td>\n",
       "      <td>33.900002</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1613195761000000000</th>\n",
       "      <td>Campus Energy Centre Campus HW Main Meter Power</td>\n",
       "      <td>32.299999</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1613195822000000000</th>\n",
       "      <td>Campus Energy Centre Campus HW Main Meter Power</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1613195882000000000</th>\n",
       "      <td>Campus Energy Centre Campus HW Main Meter Power</td>\n",
       "      <td>32.200001</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1613195942000000000</th>\n",
       "      <td>Campus Energy Centre Campus HW Main Meter Power</td>\n",
       "      <td>33.600002</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>645 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            uniqueID  \\\n",
       "DateTime                                                               \n",
       "1613112271000000000  Campus Energy Centre Campus HW Main Meter Power   \n",
       "1613112564000000000  Campus Energy Centre Campus HW Main Meter Power   \n",
       "1613112600000000000  Campus Energy Centre Campus HW Main Meter Power   \n",
       "1613112877000000000  Campus Energy Centre Campus HW Main Meter Power   \n",
       "1613113200000000000  Campus Energy Centre Campus HW Main Meter Power   \n",
       "...                                                              ...   \n",
       "1613195579000000000  Campus Energy Centre Campus HW Main Meter Power   \n",
       "1613195761000000000  Campus Energy Centre Campus HW Main Meter Power   \n",
       "1613195822000000000  Campus Energy Centre Campus HW Main Meter Power   \n",
       "1613195882000000000  Campus Energy Centre Campus HW Main Meter Power   \n",
       "1613195942000000000  Campus Energy Centre Campus HW Main Meter Power   \n",
       "\n",
       "                       val_num  realtime_anomaly  \n",
       "DateTime                                          \n",
       "1613112271000000000  39.900002              True  \n",
       "1613112564000000000  38.200001              True  \n",
       "1613112600000000000  38.299999             False  \n",
       "1613112877000000000  39.799999              True  \n",
       "1613113200000000000  39.200001              True  \n",
       "...                        ...               ...  \n",
       "1613195579000000000  33.900002              True  \n",
       "1613195761000000000  32.299999              True  \n",
       "1613195822000000000  34.000000              True  \n",
       "1613195882000000000  32.200001              True  \n",
       "1613195942000000000  33.600002              True  \n",
       "\n",
       "[645 rows x 3 columns]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniqueID</th>\n",
       "      <th>val_num</th>\n",
       "      <th>realtime_anomaly</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DateTime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1613112271000000000</th>\n",
       "      <td>Campus Energy Centre Campus HW Main Meter Power</td>\n",
       "      <td>40.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1613112564000000000</th>\n",
       "      <td>Campus Energy Centre Campus HW Main Meter Power</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1613112600000000000</th>\n",
       "      <td>Campus Energy Centre Campus HW Main Meter Power</td>\n",
       "      <td>140.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            uniqueID  val_num  \\\n",
       "DateTime                                                                        \n",
       "1613112271000000000  Campus Energy Centre Campus HW Main Meter Power     40.0   \n",
       "1613112564000000000  Campus Energy Centre Campus HW Main Meter Power   -100.0   \n",
       "1613112600000000000  Campus Energy Centre Campus HW Main Meter Power    140.0   \n",
       "\n",
       "                     realtime_anomaly  \n",
       "DateTime                               \n",
       "1613112271000000000              True  \n",
       "1613112564000000000              True  \n",
       "1613112600000000000             False  "
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar_sub = ar_df.head(3)\n",
    "ar_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.8/site-packages/pandas/core/generic.py:5494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "ar_sub.index = [int(time.time_ns()), int(time.time_ns() - 3e11), int(time.time_ns() - 6e11),]\n",
    "ar_sub.val_num = [40.0, -100.0, 140.0]\n",
    "ar_sub.realtime_anomaly = [\"True\", \"False\", \"False\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_sub.index.rename(\"DateTime\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniqueID</th>\n",
       "      <th>val_num</th>\n",
       "      <th>realtime_anomaly</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DateTime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1623719525700944000</th>\n",
       "      <td>Campus Energy Centre Campus HW Main Meter Power</td>\n",
       "      <td>40.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1623719225700943872</th>\n",
       "      <td>Campus Energy Centre Campus HW Main Meter Power</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1623718925700945920</th>\n",
       "      <td>Campus Energy Centre Campus HW Main Meter Power</td>\n",
       "      <td>140.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            uniqueID  val_num  \\\n",
       "DateTime                                                                        \n",
       "1623719525700944000  Campus Energy Centre Campus HW Main Meter Power     40.0   \n",
       "1623719225700943872  Campus Energy Centre Campus HW Main Meter Power   -100.0   \n",
       "1623718925700945920  Campus Energy Centre Campus HW Main Meter Power    140.0   \n",
       "\n",
       "                    realtime_anomaly  \n",
       "DateTime                              \n",
       "1623719525700944000             True  \n",
       "1623719225700943872            False  \n",
       "1623718925700945920            False  "
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16237406216238912"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "int(datetime.utcnow().timestamp() * 10e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # as set up in the docker-compose\n",
    "# token = \"mytoken\"\n",
    "# org = \"UBC\"\n",
    "# bucket = \"MDS2021\"\n",
    "\n",
    "# # set up influx\n",
    "# client = InfluxDBClient(url=\"http://localhost:8086\", token=token, timeout=999_000)\n",
    "# write_api = client.write_api(write_options=SYNCHRONOUS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "influx_conn.write_data(ar_sub, \"PREDICT_ANOMALY\", tags=[\"uniqueID\", \"realtime_anomaly\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_api.write(\n",
    "            bucket,\n",
    "            org,\n",
    "            record=ar_sub,\n",
    "            data_frame_measurement_name=\"aa\",\n",
    "            data_frame_tag_columns=[\"uniqueID\", \"realtime_anomaly\"],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "influx_conn.client.close()\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniqueID</th>\n",
       "      <th>model_anomaly</th>\n",
       "      <th>val_num</th>\n",
       "      <th>manual_anomaly</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DateTime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-02-05 10:48:55+00:00</th>\n",
       "      <td>Campus Energy Centre Campus HW Main Meter Power</td>\n",
       "      <td>True</td>\n",
       "      <td>19.200001</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-05 10:49:55+00:00</th>\n",
       "      <td>Campus Energy Centre Campus HW Main Meter Power</td>\n",
       "      <td>True</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-05 10:50:00+00:00</th>\n",
       "      <td>Campus Energy Centre Campus HW Main Meter Power</td>\n",
       "      <td>True</td>\n",
       "      <td>16.800001</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-05 10:52:38+00:00</th>\n",
       "      <td>Campus Energy Centre Campus HW Main Meter Power</td>\n",
       "      <td>True</td>\n",
       "      <td>18.200001</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-05 10:54:19+00:00</th>\n",
       "      <td>Campus Energy Centre Campus HW Main Meter Power</td>\n",
       "      <td>True</td>\n",
       "      <td>16.900000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  uniqueID  \\\n",
       "DateTime                                                                     \n",
       "2021-02-05 10:48:55+00:00  Campus Energy Centre Campus HW Main Meter Power   \n",
       "2021-02-05 10:49:55+00:00  Campus Energy Centre Campus HW Main Meter Power   \n",
       "2021-02-05 10:50:00+00:00  Campus Energy Centre Campus HW Main Meter Power   \n",
       "2021-02-05 10:52:38+00:00  Campus Energy Centre Campus HW Main Meter Power   \n",
       "2021-02-05 10:54:19+00:00  Campus Energy Centre Campus HW Main Meter Power   \n",
       "\n",
       "                           model_anomaly    val_num  manual_anomaly  \n",
       "DateTime                                                             \n",
       "2021-02-05 10:48:55+00:00           True  19.200001           False  \n",
       "2021-02-05 10:49:55+00:00           True  17.500000           False  \n",
       "2021-02-05 10:50:00+00:00           True  16.800001           False  \n",
       "2021-02-05 10:52:38+00:00           True  18.200001           False  \n",
       "2021-02-05 10:54:19+00:00           True  16.900000           False  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "am_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from(bucket: \"MDS2021\")\n",
    "#   |> range(start: v.timeRangeStart, stop: v.timeRangeStop)\n",
    "#   |> filter(fn: (r) => r[\"_measurement\"] == \"PREDICT_ANOMALY_TWO\")\n",
    "#   |> filter(fn: (r) => r[\"_field\"] == \"val_num\")\n",
    "#   |> filter(fn: (r) => r[\"realtime_anomaly\"] == \"True\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
