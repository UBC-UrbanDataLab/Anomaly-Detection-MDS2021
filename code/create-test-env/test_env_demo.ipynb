{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Walkthrough of the test env code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from influxdb_client import InfluxDBClient\n",
    "from influxdb_client.client.write_api import SYNCHRONOUS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import files from sibling a directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"..\")\n",
    "\n",
    "import model.clean as cl\n",
    "import model.model_trainer as mt\n",
    "import model.model_predict as mp\n",
    "from model.influx_interact import influx_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1\n",
    "Set up a local instance of influx by following the README.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2  \n",
    "`populate_influx.py`  \n",
    "Populating influx with data from csvs stored in the repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_CSVS = \"../../data/labelled-skyspark-data/\"\n",
    "CSVS_TO_LOAD = [\n",
    "    \"CEC_compiled_data_1b_updated.csv\",\n",
    "    \"CEC_compiled_data_2b_updated.csv\",\n",
    "    \"CEC_compiled_data_3b_updated.csv\",\n",
    "    \"CEC_compiled_data_4b_updated.csv\",\n",
    "    \"CEC_compiled_data_5b_updated.csv\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up influx connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as set up in the docker-compose\n",
    "token = \"mytoken\"\n",
    "org = \"UBC\"\n",
    "bucket = \"MDS2021\"\n",
    "\n",
    "# set up influx\n",
    "client = InfluxDBClient(url=\"http://localhost:8086\", token=token, timeout=999_000)\n",
    "write_api = client.write_api(write_options=SYNCHRONOUS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop over each csv, read it then write it into influx  \n",
    "\n",
    "Important note: If the influx write times out, re-run and it should work on second try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing: CEC_compiled_data_1b_updated.csv\n",
      "writing: CEC_compiled_data_2b_updated.csv\n",
      "writing: CEC_compiled_data_3b_updated.csv\n",
      "writing: CEC_compiled_data_4b_updated.csv\n",
      "writing: CEC_compiled_data_5b_updated.csv\n"
     ]
    }
   ],
   "source": [
    "for csv in CSVS_TO_LOAD:\n",
    "\n",
    "    # load and set up dataframes\n",
    "    df = pd.read_csv(PATH_TO_CSVS + csv, parse_dates=[\"Datetime\"])\n",
    "    df.rename(columns={\"Value\": \"val_num\"}, inplace=True)\n",
    "    df.rename(columns={\"ID\": \"uniqueID\"}, inplace=True)\n",
    "    df.rename(columns={\"Anomaly\": \"AH\"}, inplace=True)\n",
    "    df[\"navName\"] = \"Energy\"\n",
    "    df[\"siteRef\"] = \"Campus Energy Centre\"\n",
    "    df.set_index(\"Datetime\", drop=True, inplace=True)\n",
    "    df = df.drop([\"AH\"], axis=1)\n",
    "\n",
    "    print(\"writing: {}\".format(csv))\n",
    "    # write values\n",
    "    write_api.write(\n",
    "        bucket,\n",
    "        org,\n",
    "        record=df,\n",
    "        data_frame_measurement_name=\"READINGS\",\n",
    "        data_frame_tag_columns=[\"uniqueID\", \"navName\", \"siteRef\"],\n",
    "    )\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the `df` object to see what was written to influx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val_num</th>\n",
       "      <th>uniqueID</th>\n",
       "      <th>navName</th>\n",
       "      <th>siteRef</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-01 07:45:00</th>\n",
       "      <td>2.9</td>\n",
       "      <td>Campus Energy Centre Boiler B-1 Exhaust O2</td>\n",
       "      <td>Energy</td>\n",
       "      <td>Campus Energy Centre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 08:00:00</th>\n",
       "      <td>2.9</td>\n",
       "      <td>Campus Energy Centre Boiler B-1 Exhaust O2</td>\n",
       "      <td>Energy</td>\n",
       "      <td>Campus Energy Centre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 08:15:00</th>\n",
       "      <td>2.9</td>\n",
       "      <td>Campus Energy Centre Boiler B-1 Exhaust O2</td>\n",
       "      <td>Energy</td>\n",
       "      <td>Campus Energy Centre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 08:30:00</th>\n",
       "      <td>2.9</td>\n",
       "      <td>Campus Energy Centre Boiler B-1 Exhaust O2</td>\n",
       "      <td>Energy</td>\n",
       "      <td>Campus Energy Centre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 08:45:00</th>\n",
       "      <td>2.9</td>\n",
       "      <td>Campus Energy Centre Boiler B-1 Exhaust O2</td>\n",
       "      <td>Energy</td>\n",
       "      <td>Campus Energy Centre</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     val_num                                    uniqueID  \\\n",
       "Datetime                                                                   \n",
       "2020-01-01 07:45:00      2.9  Campus Energy Centre Boiler B-1 Exhaust O2   \n",
       "2020-01-01 08:00:00      2.9  Campus Energy Centre Boiler B-1 Exhaust O2   \n",
       "2020-01-01 08:15:00      2.9  Campus Energy Centre Boiler B-1 Exhaust O2   \n",
       "2020-01-01 08:30:00      2.9  Campus Energy Centre Boiler B-1 Exhaust O2   \n",
       "2020-01-01 08:45:00      2.9  Campus Energy Centre Boiler B-1 Exhaust O2   \n",
       "\n",
       "                    navName               siteRef  \n",
       "Datetime                                           \n",
       "2020-01-01 07:45:00  Energy  Campus Energy Centre  \n",
       "2020-01-01 08:00:00  Energy  Campus Energy Centre  \n",
       "2020-01-01 08:15:00  Energy  Campus Energy Centre  \n",
       "2020-01-01 08:30:00  Energy  Campus Energy Centre  \n",
       "2020-01-01 08:45:00  Energy  Campus Energy Centre  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now sensor data has been written to influx's READINGS bucket  \n",
    "This simulates what UDL's influx will look like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3\n",
    "`test_env_scheduled_training.py`  \n",
    "Run the training file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subset the training data for fast dev iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "TESTING = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup thresholds for anomaly detection.  \n",
    "If a training example's loss is greater than the set threshold it will be flagged as anomalous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLDS = {\n",
    "    \"Campus Energy Centre Campus HW Main Meter Power\": 0.09,\n",
    "    \"Campus Energy Centre Boiler B-1 Exhaust O2\": 0.019,\n",
    "    \"Campus Energy Centre Boiler B-1 Gas Pressure\": 0.0725,\n",
    "    \"Campus Energy Centre Campus HW Main Meter Entering Water Temperature\": 0.02938,\n",
    "    \"Campus Energy Centre Campus HW Main Meter Flow\": 0.043,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick a end time for the readings to be used for training  \n",
    "In the real implementation there will be no end_time for the training data, i.e it will train on all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "END_TIME = 1613109600"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore training with removing anomalous records, i.e only train on normal data for this specific sensor data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "REMOVE_ANOMALOUS = True\n",
    "REMOVE_ANOMALOUS_DATA = [\n",
    "    \"Campus Energy Centre Campus HW Main Meter Entering Water Temperature\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Influx connector setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"./test_env_models/\"\n",
    "scaler_path = \"./test_env_standardizers/\"\n",
    "\n",
    "# set up for influx\n",
    "token = \"mytoken\"\n",
    "org = \"UBC\"\n",
    "bucket = \"MDS2021\"\n",
    "url = \"http://localhost:8086\"\n",
    "\n",
    "influx_conn = influx_class(\n",
    "    org=org,\n",
    "    url=url,\n",
    "    bucket=bucket,\n",
    "    token=token,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the training data from influx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "influx_read_df = influx_conn.make_query(\n",
    "    location=\"Campus Energy Centre\",\n",
    "    measurement=\"READINGS\",\n",
    "    end=END_TIME,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data based on sensor ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_bucket = cl.split_sensors(influx_read_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the `main_bucket` object is a dict with the name of the sensor as the key and then the value is another dict of data objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Campus Energy Centre Boiler B-1 Exhaust O2', 'Campus Energy Centre Boiler B-1 Gas Pressure', 'Campus Energy Centre Campus HW Main Meter Entering Water Temperature', 'Campus Energy Centre Campus HW Main Meter Flow', 'Campus Energy Centre Campus HW Main Meter Power'])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_bucket.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following cell for training:\n",
    "1) Iterates over each the data sets (line 1)  \n",
    "2) Removes anomalous data if the data set has been specified (lines 4-23)  \n",
    "3) Standardizes the values for training and saves the standardizer for the prediction step (lines 25-30)  \n",
    "4) Subsets the data for faster training if specified (lines 32-33)  \n",
    "5) Sequences the values into windows for the LSTM (lines 35-37)  \n",
    "6) Fits and saves the model (line 42)  \n",
    "7) Writes the resulting data (that contains: value, anomalies detected manually, and anomalies detected in training) to influx (lines 44-57)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for : Campus Energy Centre Boiler B-1 Exhaust O2\n",
      "Epoch 1/100\n",
      "141/141 [==============================] - 6s 25ms/step - loss: 9.0091e-04 - val_loss: 1.3929\n",
      "Epoch 2/100\n",
      "141/141 [==============================] - 3s 20ms/step - loss: 3.3376e-04 - val_loss: 1.4180\n",
      "Epoch 3/100\n",
      "141/141 [==============================] - 3s 21ms/step - loss: 1.6883e-04 - val_loss: 1.4221\n",
      "Epoch 4/100\n",
      "141/141 [==============================] - 3s 22ms/step - loss: 2.1098e-04 - val_loss: 1.4232\n",
      "Training for : Campus Energy Centre Boiler B-1 Gas Pressure\n",
      "Epoch 1/100\n",
      "141/141 [==============================] - 6s 25ms/step - loss: 0.2726 - val_loss: 0.3136\n",
      "Epoch 2/100\n",
      "141/141 [==============================] - 3s 23ms/step - loss: 0.2140 - val_loss: 0.3501\n",
      "Epoch 3/100\n",
      "141/141 [==============================] - 3s 21ms/step - loss: 0.2075 - val_loss: 0.3354\n",
      "Epoch 4/100\n",
      "141/141 [==============================] - 3s 23ms/step - loss: 0.2038 - val_loss: 0.3447\n",
      "Training for : Campus Energy Centre Campus HW Main Meter Entering Water Temperature\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.8/site-packages/pandas/core/frame.py:4441: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "141/141 [==============================] - 6s 22ms/step - loss: 0.2816 - val_loss: 0.2442\n",
      "Epoch 2/100\n",
      "141/141 [==============================] - 3s 20ms/step - loss: 0.1891 - val_loss: 0.2283\n",
      "Epoch 3/100\n",
      "141/141 [==============================] - 3s 22ms/step - loss: 0.1615 - val_loss: 0.1740\n",
      "Epoch 4/100\n",
      "141/141 [==============================] - 3s 20ms/step - loss: 0.1497 - val_loss: 0.1565\n",
      "Epoch 5/100\n",
      "141/141 [==============================] - 3s 21ms/step - loss: 0.1433 - val_loss: 0.1410\n",
      "Epoch 6/100\n",
      "141/141 [==============================] - 3s 22ms/step - loss: 0.1385 - val_loss: 0.1468\n",
      "Epoch 7/100\n",
      "141/141 [==============================] - 3s 19ms/step - loss: 0.1355 - val_loss: 0.1412\n",
      "Epoch 8/100\n",
      "141/141 [==============================] - 3s 24ms/step - loss: 0.1321 - val_loss: 0.1497\n",
      "Training for : Campus Energy Centre Campus HW Main Meter Flow\n",
      "Epoch 1/100\n",
      "141/141 [==============================] - 6s 25ms/step - loss: 0.2891 - val_loss: 0.1144\n",
      "Epoch 2/100\n",
      "141/141 [==============================] - 3s 21ms/step - loss: 0.2734 - val_loss: 0.2443\n",
      "Epoch 3/100\n",
      "141/141 [==============================] - 3s 22ms/step - loss: 0.2374 - val_loss: 0.3722\n",
      "Epoch 4/100\n",
      "141/141 [==============================] - 3s 21ms/step - loss: 0.2378 - val_loss: 0.4746\n",
      "Training for : Campus Energy Centre Campus HW Main Meter Power\n",
      "Epoch 1/100\n",
      "141/141 [==============================] - 6s 25ms/step - loss: 0.2983 - val_loss: 0.2220\n",
      "Epoch 2/100\n",
      "141/141 [==============================] - 3s 22ms/step - loss: 0.2378 - val_loss: 0.2171\n",
      "Epoch 3/100\n",
      "141/141 [==============================] - 3s 22ms/step - loss: 0.2115 - val_loss: 0.1890\n",
      "Epoch 4/100\n",
      "141/141 [==============================] - 3s 22ms/step - loss: 0.1970 - val_loss: 0.1715\n",
      "Epoch 5/100\n",
      "141/141 [==============================] - 3s 22ms/step - loss: 0.1919 - val_loss: 0.1639\n",
      "Epoch 6/100\n",
      "141/141 [==============================] - 3s 22ms/step - loss: 0.1869 - val_loss: 0.1562\n",
      "Epoch 7/100\n",
      "141/141 [==============================] - 3s 21ms/step - loss: 0.1850 - val_loss: 0.1532\n",
      "Epoch 8/100\n",
      "141/141 [==============================] - 3s 21ms/step - loss: 0.1797 - val_loss: 0.1531\n",
      "Epoch 9/100\n",
      "141/141 [==============================] - 3s 22ms/step - loss: 0.1813 - val_loss: 0.1472\n",
      "Epoch 10/100\n",
      "141/141 [==============================] - 3s 21ms/step - loss: 0.1761 - val_loss: 0.1452\n",
      "Epoch 11/100\n",
      "141/141 [==============================] - 3s 21ms/step - loss: 0.1726 - val_loss: 0.1397\n",
      "Epoch 12/100\n",
      "141/141 [==============================] - 3s 21ms/step - loss: 0.1724 - val_loss: 0.1505\n",
      "Epoch 13/100\n",
      "141/141 [==============================] - 3s 23ms/step - loss: 0.1671 - val_loss: 0.1353\n",
      "Epoch 14/100\n",
      "141/141 [==============================] - 3s 20ms/step - loss: 0.1629 - val_loss: 0.1337\n",
      "Epoch 15/100\n",
      "141/141 [==============================] - 3s 21ms/step - loss: 0.1604 - val_loss: 0.1311\n",
      "Epoch 16/100\n",
      "141/141 [==============================] - 3s 22ms/step - loss: 0.1599 - val_loss: 0.1333\n",
      "Epoch 17/100\n",
      "141/141 [==============================] - 3s 19ms/step - loss: 0.1630 - val_loss: 0.1304\n",
      "Epoch 18/100\n",
      "141/141 [==============================] - 3s 21ms/step - loss: 0.1652 - val_loss: 0.1283\n",
      "Epoch 19/100\n",
      "141/141 [==============================] - 3s 22ms/step - loss: 0.1614 - val_loss: 0.1286\n",
      "Epoch 20/100\n",
      "141/141 [==============================] - 3s 24ms/step - loss: 0.1613 - val_loss: 0.1261\n",
      "Epoch 21/100\n",
      "141/141 [==============================] - 3s 22ms/step - loss: 0.1606 - val_loss: 0.1246\n",
      "Epoch 22/100\n",
      "141/141 [==============================] - 3s 22ms/step - loss: 0.1575 - val_loss: 0.1249\n",
      "Epoch 23/100\n",
      "141/141 [==============================] - 3s 20ms/step - loss: 0.1599 - val_loss: 0.1212\n",
      "Epoch 24/100\n",
      "141/141 [==============================] - 3s 20ms/step - loss: 0.1551 - val_loss: 0.1243\n",
      "Epoch 25/100\n",
      "141/141 [==============================] - 3s 22ms/step - loss: 0.1564 - val_loss: 0.1199\n",
      "Epoch 26/100\n",
      "141/141 [==============================] - 3s 20ms/step - loss: 0.1530 - val_loss: 0.1214\n",
      "Epoch 27/100\n",
      "141/141 [==============================] - 3s 21ms/step - loss: 0.1545 - val_loss: 0.1181\n",
      "Epoch 28/100\n",
      "141/141 [==============================] - 3s 20ms/step - loss: 0.1540 - val_loss: 0.1205\n",
      "Epoch 29/100\n",
      "141/141 [==============================] - 3s 22ms/step - loss: 0.1536 - val_loss: 0.1178\n",
      "Epoch 30/100\n",
      "141/141 [==============================] - 3s 19ms/step - loss: 0.1513 - val_loss: 0.1156\n",
      "Epoch 31/100\n",
      "141/141 [==============================] - 3s 20ms/step - loss: 0.1511 - val_loss: 0.1174\n",
      "Epoch 32/100\n",
      "141/141 [==============================] - 3s 21ms/step - loss: 0.1512 - val_loss: 0.1177\n",
      "Epoch 33/100\n",
      "141/141 [==============================] - 3s 21ms/step - loss: 0.1491 - val_loss: 0.1162\n"
     ]
    }
   ],
   "source": [
    "for key, df in main_bucket.items():\n",
    "    print(\"Training for : {}\".format(key))\n",
    "\n",
    "    # removes anomalies to only train on normal data\n",
    "    if REMOVE_ANOMALOUS:\n",
    "        if key in REMOVE_ANOMALOUS_DATA:\n",
    "            PATH_TO_CSVS = \"../../data/labelled-skyspark-data/\"\n",
    "            csv = \"CEC_compiled_data_2b_updated.csv\"\n",
    "            df_with_manual_anomaly = pd.read_csv(\n",
    "                PATH_TO_CSVS + csv, parse_dates=[\"Datetime\"]\n",
    "            )\n",
    "            df_with_manual_anomaly[\"Datetime\"] = pd.to_datetime(\n",
    "                df_with_manual_anomaly[\"Datetime\"], utc=True\n",
    "            )\n",
    "            df = df.merge(\n",
    "                df_with_manual_anomaly[[\"Datetime\", \"Anomaly\"]],\n",
    "                how=\"left\",\n",
    "                left_on=\"DateTime\",\n",
    "                right_on=\"Datetime\",\n",
    "            )\n",
    "            df = df.loc[df[\"Anomaly\"] == False]\n",
    "            df = df.drop(columns=[\"DateTime\"], axis=1)\n",
    "            am_df.rename(columns={\"Anomaly\": \"manual_anomaly\"}, inplace=True)\n",
    "\n",
    "    # creates standardized column for each sensor in main bucket\n",
    "    df[\"Stand_Val\"] = cl.std_val_train(\n",
    "        df[[\"Value\"]],\n",
    "        main_bucket[key][\"ID\"].any(),\n",
    "        scaler_path,\n",
    "    )\n",
    "\n",
    "    if TESTING:\n",
    "        df = df.tail(5000)\n",
    "\n",
    "    # creates arrays for sliding windows\n",
    "    x_train, y_train = mt.create_sequences(df[\"Stand_Val\"], df[\"Stand_Val\"])\n",
    "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "\n",
    "    normal_dict = cl.model_parser(df, x_train, y_train)\n",
    "\n",
    "    threshold = THRESHOLDS[key]\n",
    "    mt.fit_models(normal_dict, model_path, threshold)\n",
    "\n",
    "    # for writing AM to influx\n",
    "    am_df = normal_dict[key][\"train_score_df\"]\n",
    "    am_df.rename(columns={\"anomaly\": \"model_anomaly\"}, inplace=True)\n",
    "    am_df.rename(columns={\"ID\": \"uniqueID\"}, inplace=True)\n",
    "    am_df.rename(columns={\"Datetime\": \"DateTime\"}, inplace=True)\n",
    "    am_df[\"val_num\"] = df[\"Value\"].iloc[x_train.shape[1] :]\n",
    "    # only if it hasnt already been created earlier\n",
    "    if \"manual_anomaly\" not in set(am_df.columns):\n",
    "        am_df[\"manual_anomaly\"] = False\n",
    "    am_df.set_index(\"DateTime\", drop=True, inplace=True)\n",
    "    am_df = am_df[[\"uniqueID\", \"model_anomaly\", \"val_num\", \"manual_anomaly\"]]\n",
    "\n",
    "    influx_conn.write_data(am_df, \"TRAINING_ANOMALY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4\n",
    "`test_env_scheduled_predictor.py`  \n",
    "Create predictions and write to influx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up start and end times for the prediction data set in the test env.  \n",
    "In the real implementation END_TIME would be `now()` and START_TIME would be `now() - 1d`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# END TIME FOR TRAINING SET BECOMES PREDICTING'S START TIME\n",
    "START_TIME = 1613109600\n",
    "END_TIME = 1613196000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the data to be predicted on from influx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading data from influx\n"
     ]
    }
   ],
   "source": [
    "print(\"reading data from influx\")\n",
    "influx_read_df = influx_conn.make_query(\n",
    "    location=\"Campus Energy Centre\",\n",
    "    measurement=\"READINGS\",\n",
    "    start=START_TIME,\n",
    "    end=END_TIME,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split based on data name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_bucket = cl.split_sensors(influx_read_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following cell for predicting:\n",
    "1) Iterates over each the data sets (line 1)  \n",
    "2) Standardizes the values for training by loading the standardizer from the training step (lines 2-6)     \n",
    "3) Sequences the values into windows for the LSTM and other reshaping for the prediction step(lines 8-14)  \n",
    "4) Creates predictions for the data and returns the prediction object (lines 16-24)   \n",
    "5) Shapes the prediction object for writing back to influx (a dataframe that contains, value, and the prediction of anomalous) (lines 26-34) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Campus Energy Centre Boiler B-1 Exhaust O2\n",
      "(96, 5)\n",
      "Campus Energy Centre Boiler B-1 Gas Pressure\n",
      "(132, 5)\n",
      "Campus Energy Centre Campus HW Main Meter Entering Water Temperature\n",
      "(296, 5)\n",
      "Campus Energy Centre Campus HW Main Meter Flow\n",
      "(1386, 5)\n",
      "Campus Energy Centre Campus HW Main Meter Power\n",
      "(660, 5)\n"
     ]
    }
   ],
   "source": [
    "for key, df in main_bucket.items():\n",
    "    print(key)\n",
    "    main_bucket[key][\"Stand_Val\"] = cl.std_val_predict(\n",
    "        main_bucket[key][[\"Value\"]],\n",
    "        main_bucket[key][\"ID\"].any(),\n",
    "        scaler_path,\n",
    "    )\n",
    "    print(main_bucket[key].shape)\n",
    "\n",
    "    # creates arrays for sliding windows\n",
    "    x_train, y_train = mt.create_sequences(\n",
    "        main_bucket[key][\"Stand_Val\"], main_bucket[key][\"Stand_Val\"]\n",
    "    )\n",
    "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "    timestamps = df[\"DateTime\"].tail(len(df) - x_train.shape[1]).values\n",
    "    threshold = THRESHOLDS[key]\n",
    "\n",
    "    # predicting and prediction formatting\n",
    "    pred = mp.make_prediction(\n",
    "        key,\n",
    "        x_train,\n",
    "        timestamps,\n",
    "        threshold,\n",
    "        model_path,\n",
    "    )\n",
    "    ar_df = pd.DataFrame.from_dict(pred[\"data\"])\n",
    "\n",
    "    # prep for writing\n",
    "    ar_df.rename(columns={\"anomaly\": \"realtime_anomaly\"}, inplace=True)\n",
    "    ar_df.rename(columns={\"Timestamp\": \"DateTime\"}, inplace=True)\n",
    "    ar_df[\"uniqueID\"] = key\n",
    "    ar_df.set_index(\"DateTime\", drop=True, inplace=True)\n",
    "    ar_df[\"val_num\"] = df[\"Value\"].tail(len(df) - x_train.shape[1]).values\n",
    "    ar_df = ar_df[[\"uniqueID\", \"val_num\", \"realtime_anomaly\"]]\n",
    "\n",
    "    influx_conn.write_data(ar_df, \"PREDICT_ANOMALY_TWO\", tags=[\"uniqueID\", \"realtime_anomaly\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test environment will now have three readings:  \n",
    "READINGS: the raw data  \n",
    "TRAINING_ANOMALY: data with anomalies flag manually and during the training  \n",
    "PREDICT_ANOMALY: data with anomalies detected by the prediction step  \n",
    "\n",
    "As well as a standardizer and a model for each data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniqueID</th>\n",
       "      <th>val_num</th>\n",
       "      <th>realtime_anomaly</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DateTime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1613112271000000000</th>\n",
       "      <td>Campus Energy Centre Campus HW Main Meter Power</td>\n",
       "      <td>39.900002</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1613112564000000000</th>\n",
       "      <td>Campus Energy Centre Campus HW Main Meter Power</td>\n",
       "      <td>38.200001</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1613112600000000000</th>\n",
       "      <td>Campus Energy Centre Campus HW Main Meter Power</td>\n",
       "      <td>38.299999</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1613112877000000000</th>\n",
       "      <td>Campus Energy Centre Campus HW Main Meter Power</td>\n",
       "      <td>39.799999</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1613113200000000000</th>\n",
       "      <td>Campus Energy Centre Campus HW Main Meter Power</td>\n",
       "      <td>39.200001</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1613195579000000000</th>\n",
       "      <td>Campus Energy Centre Campus HW Main Meter Power</td>\n",
       "      <td>33.900002</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1613195761000000000</th>\n",
       "      <td>Campus Energy Centre Campus HW Main Meter Power</td>\n",
       "      <td>32.299999</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1613195822000000000</th>\n",
       "      <td>Campus Energy Centre Campus HW Main Meter Power</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1613195882000000000</th>\n",
       "      <td>Campus Energy Centre Campus HW Main Meter Power</td>\n",
       "      <td>32.200001</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1613195942000000000</th>\n",
       "      <td>Campus Energy Centre Campus HW Main Meter Power</td>\n",
       "      <td>33.600002</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>645 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            uniqueID  \\\n",
       "DateTime                                                               \n",
       "1613112271000000000  Campus Energy Centre Campus HW Main Meter Power   \n",
       "1613112564000000000  Campus Energy Centre Campus HW Main Meter Power   \n",
       "1613112600000000000  Campus Energy Centre Campus HW Main Meter Power   \n",
       "1613112877000000000  Campus Energy Centre Campus HW Main Meter Power   \n",
       "1613113200000000000  Campus Energy Centre Campus HW Main Meter Power   \n",
       "...                                                              ...   \n",
       "1613195579000000000  Campus Energy Centre Campus HW Main Meter Power   \n",
       "1613195761000000000  Campus Energy Centre Campus HW Main Meter Power   \n",
       "1613195822000000000  Campus Energy Centre Campus HW Main Meter Power   \n",
       "1613195882000000000  Campus Energy Centre Campus HW Main Meter Power   \n",
       "1613195942000000000  Campus Energy Centre Campus HW Main Meter Power   \n",
       "\n",
       "                       val_num  realtime_anomaly  \n",
       "DateTime                                          \n",
       "1613112271000000000  39.900002              True  \n",
       "1613112564000000000  38.200001              True  \n",
       "1613112600000000000  38.299999             False  \n",
       "1613112877000000000  39.799999              True  \n",
       "1613113200000000000  39.200001              True  \n",
       "...                        ...               ...  \n",
       "1613195579000000000  33.900002              True  \n",
       "1613195761000000000  32.299999              True  \n",
       "1613195822000000000  34.000000              True  \n",
       "1613195882000000000  32.200001              True  \n",
       "1613195942000000000  33.600002              True  \n",
       "\n",
       "[645 rows x 3 columns]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniqueID</th>\n",
       "      <th>val_num</th>\n",
       "      <th>realtime_anomaly</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DateTime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1613112271000000000</th>\n",
       "      <td>Campus Energy Centre Campus HW Main Meter Power</td>\n",
       "      <td>70.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1613112564000000000</th>\n",
       "      <td>Campus Energy Centre Campus HW Main Meter Power</td>\n",
       "      <td>80.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1613112600000000000</th>\n",
       "      <td>Campus Energy Centre Campus HW Main Meter Power</td>\n",
       "      <td>90.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            uniqueID  val_num  \\\n",
       "DateTime                                                                        \n",
       "1613112271000000000  Campus Energy Centre Campus HW Main Meter Power     70.0   \n",
       "1613112564000000000  Campus Energy Centre Campus HW Main Meter Power     80.0   \n",
       "1613112600000000000  Campus Energy Centre Campus HW Main Meter Power     90.0   \n",
       "\n",
       "                     realtime_anomaly  \n",
       "DateTime                               \n",
       "1613112271000000000              True  \n",
       "1613112564000000000              True  \n",
       "1613112600000000000             False  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar_sub = ar_df.head(3)\n",
    "ar_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.8/site-packages/pandas/core/generic.py:5494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "ar_sub.index = [int(time.time_ns()), int(time.time_ns() - 3e11), int(time.time_ns() - 6e11),]\n",
    "ar_sub.val_num = [-10.0, 30.0, 90.0]\n",
    "ar_sub.realtime_anomaly = [\"False\", \"False\", \"True\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_sub.index.rename(\"DateTime\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniqueID</th>\n",
       "      <th>val_num</th>\n",
       "      <th>realtime_anomaly</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DateTime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1623688989628763000</th>\n",
       "      <td>Campus Energy Centre Campus HW Main Meter Power</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1623688689628763904</th>\n",
       "      <td>Campus Energy Centre Campus HW Main Meter Power</td>\n",
       "      <td>30.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1623688389628765952</th>\n",
       "      <td>Campus Energy Centre Campus HW Main Meter Power</td>\n",
       "      <td>90.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            uniqueID  val_num  \\\n",
       "DateTime                                                                        \n",
       "1623688989628763000  Campus Energy Centre Campus HW Main Meter Power    -10.0   \n",
       "1623688689628763904  Campus Energy Centre Campus HW Main Meter Power     30.0   \n",
       "1623688389628765952  Campus Energy Centre Campus HW Main Meter Power     90.0   \n",
       "\n",
       "                    realtime_anomaly  \n",
       "DateTime                              \n",
       "1623688989628763000            False  \n",
       "1623688689628763904            False  \n",
       "1623688389628765952             True  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16237141912675590"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "int(datetime.utcnow().timestamp() * 10e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # as set up in the docker-compose\n",
    "# token = \"mytoken\"\n",
    "# org = \"UBC\"\n",
    "# bucket = \"MDS2021\"\n",
    "\n",
    "# # set up influx\n",
    "# client = InfluxDBClient(url=\"http://localhost:8086\", token=token, timeout=999_000)\n",
    "# write_api = client.write_api(write_options=SYNCHRONOUS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "influx_conn.write_data(ar_sub, \"PREDICT_ANOMALY_TREE\", tags=[\"uniqueID\", \"realtime_anomaly\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'write_api' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-dd2509e61920>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m write_api.write(\n\u001b[0m\u001b[1;32m      2\u001b[0m             \u001b[0mbucket\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m             \u001b[0morg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0mrecord\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mar_sub\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mdata_frame_measurement_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"aa\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'write_api' is not defined"
     ]
    }
   ],
   "source": [
    "write_api.write(\n",
    "            bucket,\n",
    "            org,\n",
    "            record=ar_sub,\n",
    "            data_frame_measurement_name=\"aa\",\n",
    "            data_frame_tag_columns=[\"uniqueID\", \"realtime_anomaly\"],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "influx_conn.client.close()\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from(bucket: \"MDS2021\")\n",
    "#   |> range(start: v.timeRangeStart, stop: v.timeRangeStop)\n",
    "#   |> filter(fn: (r) => r[\"_measurement\"] == \"PREDICT_ANOMALY_TWO\")\n",
    "#   |> filter(fn: (r) => r[\"_field\"] == \"val_num\")\n",
    "#   |> filter(fn: (r) => r[\"realtime_anomaly\"] == \"True\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
